{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarcasm-e2e.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUe1ycYsnkEi",
        "outputId": "7c76a56e-3b71-4179-d501-2f90654e2e24"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/sarcasm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oYdvHNapmSM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1575846a-45c8-424f-ddff-eec93c7434b3"
      },
      "source": [
        "#necessary imports\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import string \n",
        "import re\n",
        "import nltk\n",
        "import os\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmxUhgIrp7Ym"
      },
      "source": [
        "#reading dataframe\n",
        "df1 = pd.read_json(\"/content/Sarcasm_Headlines_Dataset.json\",lines=True)\n",
        "df2 = pd.read_json(\"/content/Sarcasm_Headlines_Dataset_v2.json\",lines=True)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctpv7h8XqNRx",
        "outputId": "d8790b27-8667-4890-ebd5-8878a4ce7ba2"
      },
      "source": [
        "df1.count()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_link    26709\n",
              "headline        26709\n",
              "is_sarcastic    26709\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyJU063-sJxI",
        "outputId": "59a468cd-2c65-4be9-9000-e5e824ec4b87"
      },
      "source": [
        "df2.count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "is_sarcastic    28619\n",
              "headline        28619\n",
              "article_link    28619\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YLJqAtgpH3Q",
        "outputId": "0f5cc1e3-8e72-4f42-a3e1-ac1629b778c8"
      },
      "source": [
        "df = pd.concat([df1,df2])\n",
        "df.count()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_link    55328\n",
              "headline        55328\n",
              "is_sarcastic    55328\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gghaoM_SsNp0"
      },
      "source": [
        "#removing duplicates\n",
        "df = df.drop_duplicates().reset_index(drop=True) "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Na1inquN2mUY",
        "outputId": "ae9cb295-9ab1-4a4e-b860-fe3922a7ca4c"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "article_link    28617\n",
              "headline        28617\n",
              "is_sarcastic    28617\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "RUFmKu_w2v_6",
        "outputId": "36d76c0f-3dea-4ca5-d0cb-51c6a9aa5df6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op55EoIasT99"
      },
      "source": [
        "def clean_text(text):\n",
        "\n",
        "  text = text.lower() #converted to lowercase\n",
        "\n",
        "  pattern = re.compile('https?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+') #removing link\n",
        "  text = pattern.sub('', text) #replacing link with whitespace\n",
        "  emoji = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001FFFF\"  # removing emoji, symbols, flags\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  \n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  \n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  \n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "  text = emoji.sub('',text)\n",
        "  text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-]\", \"\", text) #additional special characters removed\n",
        "  return text"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yF2epBwepEua"
      },
      "source": [
        "def token_word(dframe):\n",
        "\n",
        "  head_line = list() #new list\n",
        "  lines = dframe['headline'].values.tolist() #df values to list\n",
        "\n",
        "  for line in lines:\n",
        "    line = clean_text(line) #passing each insatnce of corpus \n",
        "    tokenize = word_tokenize(line) #NLTK tokenize function\n",
        "    pure_words = [word for word in tokenize if word.isalpha()] #keeping only alphabets\n",
        "    stop_words = set(stopwords.words(\"english\")) #loading 'English' stopwords\n",
        "    filtered_words = [ word for word in pure_words if not word in stop_words] #removing all stopwords\n",
        "    head_line.append(filtered_words) #added to the list\n",
        "\n",
        "  return head_line"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRliWATysZEg",
        "outputId": "d5b5a25e-ead7-4319-c8b6-cc0cb4daccfb"
      },
      "source": [
        "head_lines = token_word(df)\n",
        "head_lines[:5]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['former',\n",
              "  'versace',\n",
              "  'store',\n",
              "  'clerk',\n",
              "  'sues',\n",
              "  'secret',\n",
              "  'black',\n",
              "  'code',\n",
              "  'minority',\n",
              "  'shoppers'],\n",
              " ['roseanne',\n",
              "  'revival',\n",
              "  'catches',\n",
              "  'thorny',\n",
              "  'political',\n",
              "  'mood',\n",
              "  'better',\n",
              "  'worse'],\n",
              " ['mom',\n",
              "  'starting',\n",
              "  'fear',\n",
              "  'sons',\n",
              "  'web',\n",
              "  'series',\n",
              "  'closest',\n",
              "  'thing',\n",
              "  'grandchild'],\n",
              " ['boehner',\n",
              "  'wants',\n",
              "  'wife',\n",
              "  'listen',\n",
              "  'come',\n",
              "  'alternative',\n",
              "  'debtreduction',\n",
              "  'ideas'],\n",
              " ['jk', 'rowling', 'wishes', 'snape', 'happy', 'birthday', 'magical', 'way']]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLOIXRWksfTo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f080d568-4f6d-4a45-b6a1-84581e4dc74f"
      },
      "source": [
        "tokenizer_obj = tf.keras.preprocessing.text.Tokenizer() #tokenizer object\n",
        "tokenizer_obj.fit_on_texts(head_lines) #Tokenizer fit method\n",
        "word_index = tokenizer_obj.word_index #to count words\n",
        "print(f'Unique words ', len(word_index))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words  28565\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkZTvt2RsrtD"
      },
      "source": [
        "sequences = tokenizer_obj.texts_to_sequences(head_lines)\n",
        "lines_pad = tf.keras.preprocessing.sequence.pad_sequences(sequences=sequences, maxlen=25,padding='post') #to make sure each input has same length"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BQ-rOtIpdzf"
      },
      "source": [
        "sentiment = df['is_sarcastic'].values #extract output values"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52ZhtxJcnB0r"
      },
      "source": [
        "#shuffled to make sure no bias\n",
        "dimen = np.arange(lines_pad.shape[0]) \n",
        "np.random.shuffle(dimen)\n",
        "lines_pad = lines_pad[dimen]\n",
        "sentiment = sentiment[dimen]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrsVLHrQj1Z-"
      },
      "source": [
        "test_sample = int(0.2 * lines_pad.shape[0])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE1IVCu7nEUW"
      },
      "source": [
        "#train-test split\n",
        "x_train = lines_pad[:-test_sample]\n",
        "y_train = sentiment[:-test_sample]\n",
        "x_test = lines_pad[-test_sample:]\n",
        "y_test = sentiment[-test_sample:]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JJOMfVGr-Jf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f606137-9d41-493c-cdcc-45a57c524bf5"
      },
      "source": [
        "print(f' x_train = {x_train.shape} y_train = {y_train.shape} x_test = {x_test.shape} y_test = {y_test.shape} ')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " x_train = (22894, 25) y_train = (22894,) x_test = (5723, 25) y_test = (5723,) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sD7GzMy3DtaZ",
        "outputId": "fca01a7b-c7fa-424a-abde-a9143f2a43e2"
      },
      "source": [
        "ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/        Sarcasm_Headlines_Dataset.json\n",
            "\u001b[01;34msample_data\u001b[0m/  Sarcasm_Headlines_Dataset_v2.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2cji1XMDg85"
      },
      "source": [
        "os.chdir(\"drive/My Drive/sarcasm\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be7nsEzsEGTS",
        "outputId": "5a89abba-c248-4f1c-e123-966ebd9c00cd"
      },
      "source": [
        "ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.twitter.27B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kmhDvPanTl0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03fbf565-f2b1-4f1b-8db7-231f37fec5fa"
      },
      "source": [
        "#creating dict. with keys:word and values:vector\n",
        "embeddings_index = {}\n",
        "embedding_dim = 100\n",
        "f = open('glove.twitter.27B.100d.txt', encoding = \"utf-8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1193514 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dvuTpIJ6bj0",
        "outputId": "3e68482a-53b7-4699-8f48-38d6ee15283c"
      },
      "source": [
        "#creating embedding matrix to use in embedding layer\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "c = 0\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        c+=1\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print(c)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViNRMn6p0WLp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ba603a4-96eb-4f4c-9fc3-1b5d9be1a93c"
      },
      "source": [
        "type(word_index)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65mgSFLv0lzk"
      },
      "source": [
        "#Model architecture with pre-trained Glove embedding\n",
        "model = tf.keras.models.Sequential([\n",
        "                                    tf.keras.layers.Embedding(input_dim=len(word_index)+1,output_dim=embedding_dim,input_length=25,\n",
        "                                                              embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),trainable=False),\n",
        "                                    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64,dropout=0.4,recurrent_dropout=0.25)),\n",
        "                                    tf.keras.layers.Dense(units=1,activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gt0wLmVh30sG"
      },
      "source": [
        "optimizer= tf.keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4Gg1s2m9sT6"
      },
      "source": [
        "model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics='acc')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMJ9TyA99-Ht",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d51cb0f-367a-485e-c31a-ddbfeda58af1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 25, 100)           2856600   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               84480     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,941,209\n",
            "Trainable params: 84,609\n",
            "Non-trainable params: 2,856,600\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahCFRBpYmbxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d467aa9-a357-464c-9354-72d683e8de94"
      },
      "source": [
        "history= model.fit(x=x_train,y=y_train,batch_size=32,epochs=6,validation_data=(x_test,y_test),verbose=2)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "716/716 - 54s - loss: 0.5364 - acc: 0.7284 - val_loss: 0.4679 - val_acc: 0.7751\n",
            "Epoch 2/6\n",
            "716/716 - 48s - loss: 0.4729 - acc: 0.7734 - val_loss: 0.4438 - val_acc: 0.7870\n",
            "Epoch 3/6\n",
            "716/716 - 51s - loss: 0.4317 - acc: 0.7998 - val_loss: 0.4073 - val_acc: 0.8136\n",
            "Epoch 4/6\n",
            "716/716 - 49s - loss: 0.4010 - acc: 0.8168 - val_loss: 0.3923 - val_acc: 0.8198\n",
            "Epoch 5/6\n",
            "716/716 - 48s - loss: 0.3838 - acc: 0.8252 - val_loss: 0.3866 - val_acc: 0.8185\n",
            "Epoch 6/6\n",
            "716/716 - 49s - loss: 0.3651 - acc: 0.8343 - val_loss: 0.3819 - val_acc: 0.8253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ATj6i4D1Pzz",
        "outputId": "0a196a2b-10c2-4e82-b146-dd022e637276"
      },
      "source": [
        "ls"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove.twitter.27B.100d.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DvKkt_3J3mz5",
        "outputId": "ed6e08df-c8e9-4d89-bb01-c36ad941aeac"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/sarcasm'"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_Q95R6L1Wwp"
      },
      "source": [
        "model.save('my_model.h5')"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhlLUV6n2gc1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}